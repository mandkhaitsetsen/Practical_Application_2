{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.graphics.tsaplots as tsaplots\n",
    "from statsmodels.tsa.filters.filtertools import convolution_filter\n",
    "from statsmodels.tsa.seasonal import _extrapolate_trend\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from warnings import filterwarnings \n",
    "filterwarnings('ignore')\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer, TransformedTargetRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectFromModel, RFE \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = pd.read_csv('/Users/kimberlytulga/Documents/Executive Education Courses/Berkley HAAS - ML and AI Certificate/Module 11/practical_application_II_starter/data/vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = vehicles.drop(['VIN', 'odometer'], axis = 1)\n",
    "vehicles = vehicles.set_index('id')\n",
    "vehicles['year'] = vehicles['year'].fillna(1899).astype('Int64')\n",
    "#vehicles['odometer'] = vehicles['odometer'].fillna(9999999)\n",
    "vehicles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_vehicles = vehicles[vehicles['price'] <= 58000 ]\n",
    "ss_vehicles = ss_vehicles[ss_vehicles['price'] >= 500]\n",
    "#ss_vehicles = ss_vehicles[ss_vehicles['odometer'] <= 150000 ]\n",
    "ss_vehicles = ss_vehicles[ss_vehicles['year'] >= 2005 ]\n",
    "ss_vehicles = ss_vehicles[ss_vehicles['title_status'] == 'clean' ]\n",
    "ss_vehicles.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_vehicles = ss_vehicles.drop(['size','cylinders', 'condition', 'title_status'], axis = 1)\n",
    "ss_vehicles.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = ss_vehicles,  y = 'price')\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = ss_vehicles,  y = 'year')\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column to exclude\n",
    "exclude_col = 'year'\n",
    "\n",
    "# Separate columns to impute\n",
    "columns_to_impute = ss_vehicles.columns[ss_vehicles.columns != exclude_col]\n",
    "\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='constant', fill_value='unknown')\n",
    "vehicles_imputed = ss_vehicles.copy()\n",
    "vehicles_imputed[columns_to_impute] = imputer.fit_transform(vehicles_imputed[columns_to_impute])\n",
    "\n",
    "\n",
    "vehicles_imputed.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing LabelEncoder from Sklearn \n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "region_label = le.fit_transform(vehicles_imputed['region'])\n",
    "manufacturer_label = le.fit_transform(vehicles_imputed['manufacturer'])\n",
    "model_label = le.fit_transform(vehicles_imputed['model'])\n",
    "#condition_label = le.fit_transform(vehicles_imputed['condition'])\n",
    "#cylinders_label = le.fit_transform(vehicles_imputed['cylinders'])\n",
    "fuel_label = le.fit_transform(vehicles_imputed['fuel'])\n",
    "#title_status_label = le.fit_transform(vehicles_imputed['title_status'])\n",
    "transmission_label = le.fit_transform(vehicles_imputed['transmission'])\n",
    "drive_label = le.fit_transform(vehicles_imputed['drive'])\n",
    "#size_label = le.fit_transform(vehicles_imputed['size'])\n",
    "type_label = le.fit_transform(vehicles_imputed['type'])\n",
    "paint_label = le.fit_transform(vehicles_imputed['paint_color'])\n",
    "state_label = le.fit_transform(vehicles_imputed['state'])\n",
    "\n",
    "\n",
    "# removing each column from df\n",
    "# as it is of no use now.\n",
    "vehicles_imputed.drop(\"region\", axis=1, inplace=True)\n",
    "vehicles_imputed.drop(\"manufacturer\", axis=1, inplace=True)\n",
    "vehicles_imputed.drop(\"model\", axis=1, inplace=True)\n",
    "#vehicles_imputed.drop(\"condition\", axis=1, inplace=True)\n",
    "#vehicles_imputed.drop(\"cylinders\", axis=1, inplace=True)\n",
    "vehicles_imputed.drop(\"fuel\", axis=1, inplace=True)\n",
    "#vehicles_imputed.drop(\"title_status\", axis=1, inplace=True)\n",
    "vehicles_imputed.drop(\"transmission\", axis=1, inplace=True)\n",
    "vehicles_imputed.drop(\"drive\", axis=1, inplace=True)\n",
    "#vehicles_imputed.drop(\"size\", axis=1, inplace=True)\n",
    "vehicles_imputed.drop(\"type\", axis=1, inplace=True)\n",
    "vehicles_imputed.drop(\"paint_color\", axis=1, inplace=True)\n",
    "vehicles_imputed.drop(\"state\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Appending the array to our dataFrame \n",
    "# with each column name \n",
    "vehicles_imputed[\"region\"] = region_label\n",
    "vehicles_imputed[\"manufacturer\"] = manufacturer_label\n",
    "vehicles_imputed[\"model\"] = model_label\n",
    "#vehicles_imputed[\"condition\"] = condition_label\n",
    "#vehicles_imputed[\"cylinders\"] = cylinders_label\n",
    "vehicles_imputed[\"fuel\"] = fuel_label\n",
    "#vehicles_imputed[\"title_status\"] = title_status_label\n",
    "vehicles_imputed[\"transmission\"] = transmission_label\n",
    "vehicles_imputed[\"drive\"] = drive_label\n",
    "#vehicles_imputed[\"size\"] = size_label\n",
    "vehicles_imputed[\"type\"] = type_label\n",
    "vehicles_imputed[\"paint\"] = paint_label\n",
    "vehicles_imputed[\"state\"] = state_label\n",
    "\n",
    "\n",
    "# printing Dataframe\n",
    "vehicles_imputed.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking most correlated features\n",
    "\n",
    "vehicles_imputed.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corelation_maps = sns.PairGrid(vehicles_imputed)\n",
    "corelation_maps = corelation_maps.map_diag(plt.hist)\n",
    "corelation_maps = corelation_maps.map_offdiag(plt.scatter)\n",
    "corelation_maps.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vehicles_imputed.drop('price', axis = 1)\n",
    "y = vehicles_imputed['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Sequential Selector Model\n",
    "\n",
    "selector_pipe = Pipeline([ ('scaler', StandardScaler()),\n",
    "                         ('selector', SequentialFeatureSelector(LinearRegression())),\n",
    "                          ('model', LinearRegression())])\n",
    "\n",
    "selector_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'selector__n_features_to_select': [ 3, 4, 5]}\n",
    "selector_grid = GridSearchCV(selector_pipe, param_grid=param_dict)\n",
    "selector_grid.fit(X_train, y_train)\n",
    "train_preds = selector_grid.predict(X_train)\n",
    "test_preds = selector_grid.predict(X_test)\n",
    "selector_train_mse = mean_squared_error(y_train, train_preds)\n",
    "selector_test_mse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "\n",
    "# ANSWER CHECK\n",
    "print(f'Train MSE: {selector_train_mse}')\n",
    "print(f'Test MSE: {selector_test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_selector = selector_grid.score(X_test, y_test)\n",
    "R_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x = y_train, y = train_preds, title ='Train Price Predictions vs Real', labels=dict(x = 'Real Price', y = 'Predicted Price'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = selector_grid.best_estimator_\n",
    "best_selector = best_estimator.named_steps['selector']\n",
    "best_model = selector_grid.best_estimator_.named_steps['model']\n",
    "feature_names = X_train.columns[best_selector.get_support()]\n",
    "coefs = best_model.coef_\n",
    "\n",
    "print(best_estimator)\n",
    "print(f'Features from best selector: {feature_names}.')\n",
    "print('Coefficient values: ')\n",
    "print('===================')\n",
    "pd.DataFrame([coefs.T], columns = feature_names, index = ['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_df = pd.DataFrame({'feature': feature_names, 'coef': coefs})\n",
    "selector_sorted = selector_df.reindex(selector_df['coef'].abs().sort_values(ascending=False).index)\n",
    "selector_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Ridge Model\n",
    "\n",
    "ridge_param_dict = {'ridge__alpha': np.logspace(0, 10, 50)}\n",
    "ridge_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                      ('ridge', Ridge())])\n",
    "ridge_grid = GridSearchCV(ridge_pipe, param_grid=ridge_param_dict)\n",
    "print(ridge_pipe.named_steps)\n",
    "ridge_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_grid.fit(X_train, y_train)\n",
    "ridge_train_preds = ridge_grid.predict(X_train)\n",
    "ridge_test_preds = ridge_grid.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_train_preds)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_test_preds)\n",
    "print(f'Train MSE: {ridge_train_mse}')\n",
    "print(f'Test MSE: {ridge_test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ridge = ridge_grid.score(X_test, y_test)\n",
    "R_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge_estimator = ridge_grid.best_estimator_\n",
    "best_ridge_selector = best_ridge_estimator.named_steps['ridge']\n",
    "best_ridge_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge_model = ridge_grid.best_estimator_.named_steps['ridge']\n",
    "ridge_coefs = best_ridge_model.coef_\n",
    "\n",
    "ridge_df = pd.DataFrame({'feature': X_train.columns, 'coef': ridge_coefs})\n",
    "ridge_df = ridge_df.loc[ridge_df['coef'] != 0]\n",
    "ridge_sorted = ridge_df.reindex(ridge_df['coef'].abs().sort_values(ascending=False).index)\n",
    "ridge_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(ridge_grid, X_test, y_test, n_repeats=30, random_state=0)\n",
    "\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "\n",
    "    if r.importances_mean[i]  * r.importances_std[i] > 0:\n",
    "\n",
    "        print(f\"{X_train.columns[i]:<10}\"\n",
    "\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso Model\n",
    "auto_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('lasso', Lasso(random_state = 42))])\n",
    "auto_pipe.fit(X_train, y_train)\n",
    "lasso_coefs = auto_pipe.named_steps['lasso'].coef_\n",
    "\n",
    "print(type(lasso_coefs))\n",
    "auto_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_train_mse = mean_squared_error(y_train, auto_pipe.predict(X_train))\n",
    "lasso_test_mse = mean_squared_error(y_test, auto_pipe.predict(X_test))\n",
    "\n",
    "print(lasso_train_mse)\n",
    "print(lasso_test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_lasso = auto_pipe.score(X_test, y_test)\n",
    "R_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_df = pd.DataFrame({'feature': X_train.columns, 'coef': lasso_coefs})\n",
    "lasso_df =lasso_df.loc[lasso_df['coef'] != 0]\n",
    "lasso_sorted = lasso_df.reindex(lasso_df['coef'].abs().sort_values(ascending=False).index)\n",
    "lasso_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso as a feature Selector\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectFromModel\n",
    "\n",
    "lasso_selector_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                                ('selector', SelectFromModel(Lasso())),\n",
    "                                    ('linreg', LinearRegression())])\n",
    "lasso_selector_pipe.fit(X_train, y_train)\n",
    "lasso_selector_train_mse = mean_squared_error(y_train, lasso_selector_pipe.predict(X_train))\n",
    "lasso_selector_test_mse = mean_squared_error(y_test, lasso_selector_pipe.predict(X_test))\n",
    "\n",
    "print(lasso_selector_train_mse)\n",
    "print(lasso_selector_test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_lasso_selector = lasso_selector_pipe.score(X_test, y_test)\n",
    "R_lasso_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Coefficients for each features\n",
    "feature_names = X_train.columns\n",
    "\n",
    "lasso_selected_feature = lasso_selector_pipe.named_steps['selector']\n",
    "# Get the support mask of selected features\n",
    "lasso_selected_feature_mask = lasso_selected_feature.get_support()\n",
    "lasso_selected_feature_names = [feature_names[i] for i in range(len(feature_names)) if lasso_selected_feature_mask[i]]\n",
    "lasso_selector_model = lasso_selected_feature.estimator_\n",
    "lasso_selector_coefs = lasso_selector_model.coef_\n",
    "\n",
    "\n",
    "lasso_selector_df = pd.DataFrame({'feature': lasso_selected_feature_names, 'coef': lasso_selector_coefs})\n",
    "lasso_selector_sorted = lasso_selector_df.reindex(lasso_selector_df['coef'].abs().sort_values(ascending=False).index)\n",
    "lasso_selector_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RFE with Lasso\n",
    "\n",
    "lasso = Lasso() \n",
    "rfe = RFE(estimator=lasso, n_features_to_select=5)\n",
    "\n",
    "# Define a pipeline with scaling and RFE\n",
    "rfe_lasso_pipe = Pipeline([\n",
    "                    ('scaler', StandardScaler()),  # Scale features\n",
    "                    ('feature_selection', rfe),    # Perform RFE\n",
    "                    ('model', lasso)               # Final model\n",
    "                    ])\n",
    "rfe_lasso_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Get the support mask of selected features\n",
    "rfe_lasso_selected_features = rfe_lasso_pipe.named_steps['feature_selection'].support_\n",
    "\n",
    "# Indices and names of the selected features\n",
    "feature_names = X.columns\n",
    "rfe_lasso_selected_feature_names = feature_names[rfe_lasso_selected_features]\n",
    "\n",
    "\n",
    "rfe_lasso_train_mse = mean_squared_error(y_train, rfe_lasso_pipe.predict(X_train))\n",
    "rfe_lasso_test_mse = mean_squared_error(y_test, rfe_lasso_pipe.predict(X_test))\n",
    "\n",
    "\n",
    "print(f'RFE Lasso Selector Train MSE: {rfe_lasso_train_mse}')\n",
    "print(f'RFE Lasso Selector Test MSE: {rfe_lasso_test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_lasso_selected_coefs = rfe_lasso_pipe.named_steps['model'].coef_\n",
    "\n",
    "\n",
    "rfe_lasso_selected_df = pd.DataFrame({'feature': rfe_lasso_selected_feature_names, 'coef': rfe_lasso_selected_coefs})\n",
    "rfe_lasso_selected_sorted = rfe_lasso_selected_df.reindex(rfe_lasso_selected_df['coef'].abs().sort_values(ascending=False).index)\n",
    "rfe_lasso_selected_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rfe = rfe_lasso_pipe.score(X_test, y_test)\n",
    "R_rfe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight on drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_features_name = selector_sorted.reset_index(drop=True)['feature']\n",
    "selector_features_list = ', '.join(map(str, selector_features_name))\n",
    "\n",
    "ridge_features_name = ridge_sorted.reset_index(drop=True)['feature'][:5]\n",
    "ridge_features_list = ', '.join(map(str, ridge_features_name))\n",
    "\n",
    "lasso_features_name = lasso_sorted.reset_index(drop=True)['feature'][:5]\n",
    "lasso_features_list = ', '.join(map(str, lasso_features_name))\n",
    "\n",
    "lasso_selector_features_name = lasso_selector_sorted.reset_index(drop=True)['feature'][:5]\n",
    "lasso_selector_features_list = ', '.join(map(str, lasso_features_name))\n",
    "\n",
    "\n",
    "rfe_lasso_features_name = rfe_lasso_selected_sorted .reset_index(drop=True)['feature']\n",
    "rfe_lasso_features_list = ', '.join(map(str, rfe_lasso_features_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "selection_methods = ['Sequential Selector', 'Ridge', 'Lasso','Sequential Selector with Lasso', 'Recursive Feature Elimination with Lasso']\n",
    "comparison_columns = ['Train MSE', 'Test MSE', 'R^2 Score', 'Selected Features']\n",
    "comparison_table = pd.DataFrame( index = selection_methods, columns = comparison_columns)\n",
    "comparison_table['Train MSE'] = [f\"{selector_train_mse:,.0f}\", f\"{ridge_train_mse:,.0f}\", f\"{lasso_train_mse:,.0f}\", f\"{lasso_selector_train_mse:,.0f}\", f\"{rfe_lasso_train_mse:,.0f}\"]\n",
    "comparison_table['Test MSE'] = [f\"{selector_test_mse:,.0f}\", f\"{ridge_test_mse:,.0f}\", f\"{lasso_test_mse:,.0f}\",f\"{lasso_selector_test_mse:,.0f}\", f\"{rfe_lasso_test_mse:,.0f}\"]\n",
    "comparison_table['R^2 Score'] = [\"{:.1%}\".format(R_selector),\"{:.1%}\".format(R_ridge),\"{:.1%}\".format(R_lasso),\"{:.1%}\".format(R_lasso_selector),\"{:.1%}\".format(R_rfe)]\n",
    "comparison_table['Selected Features'] = [selector_features_list, ridge_features_list,  lasso_features_list , lasso_selector_features_list, rfe_lasso_features_list ]\n",
    "comparison_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(ss_vehicles, x = \"year\", y =\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(ss_vehicles, x = \"transmission\", y =\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(ss_vehicles, x = \"fuel\", y =\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(ss_vehicles, x = \"drive\", y =\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(ss_vehicles, x = \"manufacturer\", y =\"price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "Given all five models are pretty bad at predicting the price, I believe there are too many unknowns to build effective prediction model. I will cut sample size and get rid of some outliers in the Price, Year, and Odometer. I would limit my price under $58,0000, cutoff the year to oldest at 2005, and limit the odometer to 150,000 miles and re-run my analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\":(16, 6)}) #width=16, #height=6\n",
    "fig = sns.countplot(ss_vehicles, x = 'manufacturer' , order=ss_vehicles['manufacturer'].value_counts().index).set(title='Most Popular Manufacturer')\n",
    "plt.xticks(rotation = 60)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine tuning their inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
